{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ff3e9f-6894-4e3a-bbe8-653e23113540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lmqg import TransformersQG\n",
    "import speech_recognition as sr\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from lmqg.exceptions import AnswerNotFoundError\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026d6cf-2284-4b91-a267-a0d5d2142df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b3e93f-2f68-4c98-bfbe-ece2b66bc0f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to scrape paragraphs from a Wikipedia URL\n",
    "def scrape_paragraphs(topic, num_paragraphs):\n",
    "    f_topic = topic.capitalize()\n",
    "    f_topic = '_'.join(f_topic.split()).lower()\n",
    "\n",
    "    url = f'https://en.wikipedia.org/wiki/{f_topic}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    paragraphs = soup.find_all('p')[:num_paragraphs]  # Limiting the number of paragraphs\n",
    "    paragraph_texts = [p.get_text() for p in paragraphs]\n",
    "\n",
    "    return paragraph_texts\n",
    "\n",
    "# Function to generate questions from a paragraph using LMGQ\n",
    "def generate_questions(paragraph):\n",
    "    try:\n",
    "        model = TransformersQG(language=\"en\")\n",
    "        qa = model.generate_qa(paragraph)\n",
    "        return qa\n",
    "    except AnswerNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Error: No answer candidates found\"\n",
    "\n",
    "# Class to handle speech recognition for user answers\n",
    "class AnswerRecorder:\n",
    "    def __init__(self):\n",
    "        self.response = \"\"\n",
    "\n",
    "    def record_response(self):\n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Speak now:\")\n",
    "            recognizer.adjust_for_ambient_noise(source)  # Adjust for noise\n",
    "            audio = recognizer.listen(source)\n",
    "\n",
    "        try:\n",
    "            self.response = recognizer.recognize_google(audio)\n",
    "            print(\"You said:\", self.response)\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, I couldn't understand what you said.\")\n",
    "        except sr.RequestError as e:\n",
    "            print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "# Function to compute cosine similarity between two strings\n",
    "def compute_similarity(answer1, answer2):\n",
    "    vectorizer = CountVectorizer().fit_transform([answer1, answer2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    return cosine_similarity(vectors)[0, 1]\n",
    "\n",
    "# Example usage:\n",
    "topic = input(\"Enter the topic you want to interview about: \")\n",
    "num_paragraphs = int(input(\"Enter the number of paragraphs to scrape: \"))\n",
    "\n",
    "# Scrape paragraphs from Wikipedia\n",
    "paragraphs = scrape_paragraphs(topic, num_paragraphs)\n",
    "\n",
    "# Generate questions from the scraped paragraphs\n",
    "questions = [generate_questions(paragraph) for paragraph in paragraphs]\n",
    "\n",
    "# Initialize AnswerRecorder\n",
    "answer_recorder = AnswerRecorder()\n",
    "\n",
    "# Ask questions one by one and record user answers\n",
    "user_answers = []\n",
    "for question, paragraph in zip(questions, paragraphs):\n",
    "    print(\"Question:\", question)\n",
    "    answer_recorder.record_response()\n",
    "    user_answer = answer_recorder.response\n",
    "    user_answers.append(user_answer)\n",
    "    \n",
    "    lmqg_answer = generate_questions(paragraph)  # LMGQ-generated answer\n",
    "    similarity = compute_similarity(user_answer, lmqg_answer)\n",
    "    print(\"Similarity:\", similarity)\n",
    "\n",
    "# Create a DataFrame to store questions and user answers\n",
    "qa_df = pd.DataFrame({'Questions': questions, 'User_Answers': user_answers})\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "qa_df.to_excel('user_answers.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c743b72e-eaf7-4fbd-afc3-01bb2b457ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lmqg import TransformersQG\n",
    "from lmqg.exceptions import AnswerNotFoundError  # Import AnswerNotFoundError\n",
    "import speech_recognition as sr\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to scrape paragraphs from a Wikipedia URL\n",
    "def scrape_paragraphs(topic, num_paragraphs):\n",
    "    f_topic = topic.capitalize()\n",
    "    f_topic = '_'.join(f_topic.split()).lower()\n",
    "\n",
    "    url = f'https://en.wikipedia.org/wiki/{f_topic}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    paragraphs = soup.find_all('p')[:num_paragraphs]  # Limiting the number of paragraphs\n",
    "    paragraph_texts = [p.get_text() for p in paragraphs]\n",
    "\n",
    "    return paragraph_texts\n",
    "\n",
    "# Function to generate a question from a paragraph using LMQG\n",
    "def generate_question(paragraph):\n",
    "    try:\n",
    "        model = TransformersQG(language=\"en\")\n",
    "        question = model.generate_qa(paragraph)[0][0]  # Only the first question\n",
    "        return question\n",
    "    except AnswerNotFoundError:\n",
    "        return \"Error: No answer candidates found\"\n",
    "\n",
    "# Function to record speech input from the user\n",
    "def record_response():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Speak now:\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "    try:\n",
    "        response = recognizer.recognize_google(audio)\n",
    "        print(\"You said:\", response)\n",
    "        return response\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I could not understand what you said.\")\n",
    "        return \"\"\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "        return \"\"\n",
    "\n",
    "# Function to compute cosine similarity between two strings\n",
    "def compute_similarity(answer1, answer2):\n",
    "    vectorizer = CountVectorizer().fit_transform([answer1, answer2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    return cosine_similarity(vectors)[0, 1]\n",
    "\n",
    "# Example usage:\n",
    "topic = input(\"Enter the topic you want to interview about: \")\n",
    "num_paragraphs = int(input(\"Enter the number of paragraphs to scrape: \"))\n",
    "\n",
    "# Scrape paragraphs from Wikipedia\n",
    "paragraphs = scrape_paragraphs(topic, num_paragraphs)\n",
    "\n",
    "# Initialize AnswerRecorder\n",
    "answer_recorder = AnswerRecorder()\n",
    "\n",
    "# Ask questions one by one and record user answers\n",
    "for paragraph in paragraphs:\n",
    "    question = generate_question(paragraph)\n",
    "    print(\"Question:\", question)\n",
    "    \n",
    "    # Record user's response\n",
    "    user_answer = record_response()\n",
    "    if user_answer:\n",
    "        # Generate LMQG answer for the same question\n",
    "        lmqg_answer = generate_answer(paragraph, question)  # You need to implement this function\n",
    "\n",
    "        # Compute similarity between user's answer and LMQG answer\n",
    "        similarity = compute_similarity(user_answer, lmqg_answer)\n",
    "        print(\"Similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c98ce9-b322-468f-bb98-8efa7b0b14ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
