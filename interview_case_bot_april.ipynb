{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21e8bac-c47d-4d7b-9192-6ea67ca6aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lmqg import TransformersQG\n",
    "from lmqg.exceptions import AnswerNotFoundError\n",
    "import speech_recognition as sr\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62830b5f-fea2-4b3c-9a01-89a304393423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the topic you want to interview about:  Air pollution\n",
      "Enter the number of paragraphs to scrape:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prish\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:732: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prish\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1123: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prish\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:2875: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████| 1/1 [00:00<00:00, 340.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Error: No answer candidates found for this para\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prish\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:732: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prish\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1123: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████| 4/4 [00:00<00:00, 222.45it/s]\n",
      "100%|███████████████████████████| 4/4 [00:00<00:00, 420.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are substances that are harmful to the health of humans and other living beings?\n",
      "Speak now:\n",
      "You said: pollutants in the air\n",
      "Similarity: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prish\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:732: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prish\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1123: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prish\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:2875: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████| 2/2 [00:00<00:00, 992.62it/s]\n",
      "100%|██████████████████████████| 2/2 [00:00<00:00, 1984.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is air quality closely related to?\n",
      "Speak now:\n",
      "You said: ecosystem of the earth\n",
      "Similarity: 0.25\n",
      "Your answer seems quite different and may not be entirely correct. Here's the suggested answer:\n",
      "LMQG Answer: Earth's climate and ecosystems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prish\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:732: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prish\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1123: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prish\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:2875: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████| 3/3 [00:00<00:00, 746.67it/s]\n",
      "100%|███████████████████████████| 1/1 [00:00<00:00, 499.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What does poor air quality affect?\n",
      "Speak now:\n",
      "Sorry, I could not understand what you said.\n"
     ]
    }
   ],
   "source": [
    "def scrape_paragraphs(topic, num_paragraphs):\n",
    "    f_topic = topic.capitalize()\n",
    "    f_topic = '_'.join(f_topic.split()).lower()\n",
    "\n",
    "    url=f'https://en.wikipedia.org/wiki/{f_topic}'\n",
    "    response=requests.get(url)\n",
    "    soup=BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    paragraphs=soup.find_all('p')[:num_paragraphs]\n",
    "    paragraph_texts=[p.get_text() for p in paragraphs]\n",
    "\n",
    "    return paragraph_texts\n",
    "\n",
    "#question from a paragraph using LMQG\n",
    "def generate_question(paragraph):\n",
    "    try:\n",
    "        model=TransformersQG(language=\"en\")\n",
    "        result=model.generate_qa(paragraph)\n",
    "        \n",
    "        question=result[0][0]\n",
    "        answer=result[0][1]\n",
    "        return question,answer\n",
    "    except AnswerNotFoundError:\n",
    "        return \"Error: No answer candidates found\"\n",
    "\n",
    "#record speech input from the user\n",
    "class AnswerRecorder:\n",
    "    def __init__(self):\n",
    "        self.response = \"\"\n",
    "    def record_response(self):\n",
    "        recognizer =sr.Recognizer()\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Speak now:\")\n",
    "            recognizer.adjust_for_ambient_noise(source)\n",
    "            audio=recognizer.listen(source)\n",
    "        try:\n",
    "            response=recognizer.recognize_google(audio)\n",
    "            print(\"You said:\", response)\n",
    "            return response\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, I could not understand what you said.\")\n",
    "            return \"\"\n",
    "        except sr.RequestError as e:\n",
    "            print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "            return \"\"\n",
    "\n",
    "#compute cosine similarity between user answer and lmqg answer\n",
    "def compute_similarity(answer1, answer2):\n",
    "    vectorizer=CountVectorizer().fit_transform([answer1, answer2])\n",
    "    vectors=vectorizer.toarray()\n",
    "    return cosine_similarity(vectors)[0, 1]\n",
    "\n",
    "\n",
    "topic= input(\"Enter the topic you want to interview about: \")\n",
    "num_paragraphs=int(input(\"Enter the number of paragraphs to scrape: \")) #ensures exact depth of conversation you want\n",
    "\n",
    "paragraphs=scrape_paragraphs(topic, num_paragraphs)\n",
    "answer_recorder = AnswerRecorder()\n",
    "user_answers=[]\n",
    "#loop of interview\n",
    "for paragraph in paragraphs:\n",
    "    q_a_pair=generate_question(paragraph)\n",
    "\n",
    "    if len(q_a_pair)==2:\n",
    "        question,lmqg_answer=q_a_pair\n",
    "        print(\"Question:\", question)\n",
    "    \n",
    "        user_answer = answer_recorder.record_response()\n",
    "        user_answers.append(user_answer)\n",
    "        if user_answer:\n",
    "        \n",
    "            similarity = compute_similarity(user_answer, lmqg_answer)\n",
    "            print(\"Similarity:\", similarity)\n",
    "\n",
    "            if similarity <= 0.5:\n",
    "                print(\"Your answer seems quite different and may not be entirely correct. Here's the suggested answer:\")\n",
    "                print(\"LMQG Answer:\", lmqg_answer)\n",
    "    else:\n",
    "        print(\" Error: No answer candidates found for this para\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446e6c5-b6e6-4f89-9fa6-e7144f134f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
